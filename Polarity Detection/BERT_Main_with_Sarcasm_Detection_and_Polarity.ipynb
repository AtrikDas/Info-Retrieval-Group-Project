{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BERT_Main_with_Sarcasm_Detection_and_Polarity.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c346e68e5ca749e4bf3f1e03b1ce1296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b77ff0a98bec4e4eb6cfaa03b6a5b763",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f8bcf8bee8fe48808afa01559f5a42d0",
              "IPY_MODEL_97b6c27e71f44a3393285fb7a519d85c"
            ]
          }
        },
        "b77ff0a98bec4e4eb6cfaa03b6a5b763": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f8bcf8bee8fe48808afa01559f5a42d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_206af872b8184aec91354ebe8d362c56",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_38b504c2e55b4ea692e1babb613d1bf1"
          }
        },
        "97b6c27e71f44a3393285fb7a519d85c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b3f2c6627f854b6cb32d840daec02a8a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 3.06MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_21e9a51e2a384d60886ce38577264d16"
          }
        },
        "206af872b8184aec91354ebe8d362c56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "38b504c2e55b4ea692e1babb613d1bf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b3f2c6627f854b6cb32d840daec02a8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "21e9a51e2a384d60886ce38577264d16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b37cf67a6a1c4ee88e4938c2759de267": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a20bc41ef9b14cccbe66af1347018842",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_03b95dd5c6d94bf59ef6fc029c751322",
              "IPY_MODEL_922852ce574a4579abd694c12aa021bf"
            ]
          }
        },
        "a20bc41ef9b14cccbe66af1347018842": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "03b95dd5c6d94bf59ef6fc029c751322": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_60b825d0d3c1470fa050d3f011fa347f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c16d049b1d9943359f254ea0f5241b2a"
          }
        },
        "922852ce574a4579abd694c12aa021bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7b3a6bb3158c4c7c939e16ddbd9ed710",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 5.01kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_02c113aee49b41c1af2b66afb3ad9803"
          }
        },
        "60b825d0d3c1470fa050d3f011fa347f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c16d049b1d9943359f254ea0f5241b2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b3a6bb3158c4c7c939e16ddbd9ed710": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "02c113aee49b41c1af2b66afb3ad9803": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "32303fe679004ca3a38b56abff09e73e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c4c0123141ba4fda9a1ad40c89e87521",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7b7c49c4f7ad4c3b823ce55e0a3dd9bb",
              "IPY_MODEL_8cffda280e1041e4b070717aa6aedaea"
            ]
          }
        },
        "c4c0123141ba4fda9a1ad40c89e87521": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b7c49c4f7ad4c3b823ce55e0a3dd9bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_11969b969ff54b3ca55187624f39e556",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f07f98b22190476dab9db7a5ee170aa1"
          }
        },
        "8cffda280e1041e4b070717aa6aedaea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a76b46cc520b4f9daebcd1bd0a9e23c3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:09&lt;00:00, 48.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1e30866b5b2f4424ac5d2afbde43d9a4"
          }
        },
        "11969b969ff54b3ca55187624f39e556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f07f98b22190476dab9db7a5ee170aa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a76b46cc520b4f9daebcd1bd0a9e23c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1e30866b5b2f4424ac5d2afbde43d9a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5tUoHe9FRhs"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr7BCHS-nIRW",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43932c3d-76be-4b5f-d68d-7d7c3fd97ae5"
      },
      "source": [
        "!pip install transformers==4.3.3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "from torch.nn import BCEWithLogitsLoss, BCELoss\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score\n",
        "from transformers import AutoModel, AutoTokenizer \n",
        "import pickle\n",
        "from transformers import *\n",
        "from tqdm import tqdm, trange\n",
        "from ast import literal_eval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==4.3.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/54/5ca07ec9569d2f232f3166de5457b63943882f7950ddfcc887732fc7fb23/transformers-4.3.3-py3-none-any.whl (1.9MB)\n",
            "\r\u001b[K     |▏                               | 10kB 21.0MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 28.7MB/s eta 0:00:01\r\u001b[K     |▌                               | 30kB 33.7MB/s eta 0:00:01\r\u001b[K     |▊                               | 40kB 32.0MB/s eta 0:00:01\r\u001b[K     |▉                               | 51kB 32.1MB/s eta 0:00:01\r\u001b[K     |█                               | 61kB 34.4MB/s eta 0:00:01\r\u001b[K     |█▏                              | 71kB 28.6MB/s eta 0:00:01\r\u001b[K     |█▍                              | 81kB 29.5MB/s eta 0:00:01\r\u001b[K     |█▌                              | 92kB 26.5MB/s eta 0:00:01\r\u001b[K     |█▊                              | 102kB 27.9MB/s eta 0:00:01\r\u001b[K     |██                              | 112kB 27.9MB/s eta 0:00:01\r\u001b[K     |██                              | 122kB 27.9MB/s eta 0:00:01\r\u001b[K     |██▎                             | 133kB 27.9MB/s eta 0:00:01\r\u001b[K     |██▍                             | 143kB 27.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 153kB 27.9MB/s eta 0:00:01\r\u001b[K     |██▊                             | 163kB 27.9MB/s eta 0:00:01\r\u001b[K     |███                             | 174kB 27.9MB/s eta 0:00:01\r\u001b[K     |███                             | 184kB 27.9MB/s eta 0:00:01\r\u001b[K     |███▎                            | 194kB 27.9MB/s eta 0:00:01\r\u001b[K     |███▌                            | 204kB 27.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 215kB 27.9MB/s eta 0:00:01\r\u001b[K     |███▉                            | 225kB 27.9MB/s eta 0:00:01\r\u001b[K     |████                            | 235kB 27.9MB/s eta 0:00:01\r\u001b[K     |████▏                           | 245kB 27.9MB/s eta 0:00:01\r\u001b[K     |████▎                           | 256kB 27.9MB/s eta 0:00:01\r\u001b[K     |████▌                           | 266kB 27.9MB/s eta 0:00:01\r\u001b[K     |████▋                           | 276kB 27.9MB/s eta 0:00:01\r\u001b[K     |████▉                           | 286kB 27.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 296kB 27.9MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 307kB 27.9MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 317kB 27.9MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 327kB 27.9MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 337kB 27.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 348kB 27.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 358kB 27.9MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 368kB 27.9MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 378kB 27.9MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 389kB 27.9MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 399kB 27.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 409kB 27.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 419kB 27.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 430kB 27.9MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 440kB 27.9MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 450kB 27.9MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 460kB 27.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 471kB 27.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 481kB 27.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 491kB 27.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 501kB 27.9MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 512kB 27.9MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 522kB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 532kB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 542kB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 552kB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 563kB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 573kB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 583kB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 593kB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 604kB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 614kB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 624kB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 634kB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 645kB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 655kB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 665kB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 675kB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 686kB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 696kB 27.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 706kB 27.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 716kB 27.9MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 727kB 27.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 737kB 27.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 747kB 27.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 757kB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 768kB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 778kB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 788kB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 798kB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 808kB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 819kB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 829kB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 839kB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 849kB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 860kB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 870kB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 880kB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 890kB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 901kB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 911kB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 921kB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 931kB 27.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 942kB 27.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 952kB 27.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 962kB 27.9MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 972kB 27.9MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 983kB 27.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 993kB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.0MB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.0MB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.0MB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.0MB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.0MB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.1MB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.1MB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.1MB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.1MB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.1MB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.1MB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.1MB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.1MB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.1MB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.1MB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.2MB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.2MB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.2MB 27.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.2MB 27.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.2MB 27.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.2MB 27.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.2MB 27.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.2MB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.2MB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.2MB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.3MB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.3MB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.3MB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.3MB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.3MB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.3MB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.3MB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.3MB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.3MB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.4MB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.4MB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.4MB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.4MB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.4MB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.4MB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.4MB 27.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.4MB 27.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.4MB 27.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.4MB 27.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.5MB 27.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.5MB 27.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.5MB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.5MB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.5MB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.5MB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.5MB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.5MB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.5MB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.5MB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.6MB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.6MB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.6MB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.6MB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.6MB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.6MB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.6MB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.6MB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.6MB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.6MB 27.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.7MB 27.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.7MB 27.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.7MB 27.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.7MB 27.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.7MB 27.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.7MB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.7MB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.7MB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.7MB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.8MB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.8MB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.8MB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.8MB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.8MB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.8MB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.8MB 27.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.8MB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.8MB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.8MB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.9MB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.9MB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.9MB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.9MB 27.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.9MB 27.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.9MB 27.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3) (4.0.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 41.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3) (20.9)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 44.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3) (2020.12.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.3.3) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.3.3) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.3.3) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3) (1.0.1)\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3VYEJpwW_Qb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "02db7fff-caac-4138-973f-20b2d3667298"
      },
      "source": [
        "raw_df = pd.read_csv('train_polarity_sarcasm.csv')\n",
        "raw_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>content</th>\n",
              "      <th>Pro Trump</th>\n",
              "      <th>Pro Biden</th>\n",
              "      <th>Neutral</th>\n",
              "      <th>one_hot_labels</th>\n",
              "      <th>sarcasm_labels</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>True #Trump got to the white working underclas...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[0 0 1]</td>\n",
              "      <td>regular</td>\n",
              "      <td>POSITIVE\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Uh oh! @Twitter stops me from posting new emai...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1 0 0]</td>\n",
              "      <td>regular</td>\n",
              "      <td>POSITIVE\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Gildan Now Available At The Lowest Price Of Th...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[0 0 1]</td>\n",
              "      <td>regular</td>\n",
              "      <td>POSITIVE\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>So happy for our fellow Americans ,yâ€™all vot...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[0 1 0]</td>\n",
              "      <td>regular</td>\n",
              "      <td>POSITIVE\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>@NZim22 @CollinKelley @Fred_Jackson__ @realDon...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1 0 0]</td>\n",
              "      <td>regular</td>\n",
              "      <td>NEGATIVE\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  ... sarcasm_labels    polarity\n",
              "0           0             0  ...        regular  POSITIVE\\n\n",
              "1           1             1  ...        regular  POSITIVE\\n\n",
              "2           2             2  ...        regular  POSITIVE\\n\n",
              "3           3             3  ...        regular  POSITIVE\\n\n",
              "4           4             4  ...        regular  NEGATIVE\\n\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWuN_xLGdAoK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "7abd306d-fd8c-44c4-9509-93934c4526ce"
      },
      "source": [
        "print(raw_df.shape)\n",
        "df = raw_df[[\"content\", \"Pro Trump\", \"Pro Biden\", \"Neutral\", \"sarcasm_labels\", \"polarity\"]]\n",
        "df = df[df['content'].notna()]\n",
        "df = df[df['Pro Biden'].notna()]\n",
        "df = df[df['Pro Trump'].notna()]\n",
        "df = df[df['Neutral'].notna()]\n",
        "df = df[df['sarcasm_labels'].notna()]\n",
        "df = df[df['polarity'].notna()]\n",
        "print(df.shape)\n",
        "df = df.astype({\"Pro Trump\": int, \"Pro Biden\": int, \"Neutral\": int})\n",
        "df.drop_duplicates(subset='content', keep='first', inplace=True)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1979, 9)\n",
            "(1979, 6)\n",
            "(1979, 6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>Pro Trump</th>\n",
              "      <th>Pro Biden</th>\n",
              "      <th>Neutral</th>\n",
              "      <th>sarcasm_labels</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>True #Trump got to the white working underclas...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>regular</td>\n",
              "      <td>POSITIVE\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Uh oh! @Twitter stops me from posting new emai...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>regular</td>\n",
              "      <td>POSITIVE\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gildan Now Available At The Lowest Price Of Th...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>regular</td>\n",
              "      <td>POSITIVE\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>So happy for our fellow Americans ,yâ€™all vot...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>regular</td>\n",
              "      <td>POSITIVE\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@NZim22 @CollinKelley @Fred_Jackson__ @realDon...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>regular</td>\n",
              "      <td>NEGATIVE\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content  ...    polarity\n",
              "0  True #Trump got to the white working underclas...  ...  POSITIVE\\n\n",
              "1  Uh oh! @Twitter stops me from posting new emai...  ...  POSITIVE\\n\n",
              "2  Gildan Now Available At The Lowest Price Of Th...  ...  POSITIVE\\n\n",
              "3  So happy for our fellow Americans ,yâ€™all vot...  ...  POSITIVE\\n\n",
              "4  @NZim22 @CollinKelley @Fred_Jackson__ @realDon...  ...  NEGATIVE\\n\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEXi8QFKqC4v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68a8300b-998a-425c-a8fb-573a3a775445"
      },
      "source": [
        "df[\"sarcasm\"] = 0\n",
        "\n",
        "for i in range(len(df)):\n",
        "    if df[\"sarcasm_labels\"].iloc[i] == \"sarcasm\":\n",
        "        df[\"sarcasm\"].iloc[i] = 1\n",
        "    elif df[\"sarcasm_labels\"].iloc[i] != \"regular\":\n",
        "        print(f\"ERROR - unexpected label at index {i}\")\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckNSqKaxw7A4",
        "outputId": "6bb534cb-120a-4bb0-9ebd-5918299c1cdf"
      },
      "source": [
        "df[\"polarities\"] = \"00\"\n",
        "\n",
        "for i in range(len(df)):\n",
        "    if df[\"polarity\"].iloc[i] == \"POSITIVE\\n\":\n",
        "      df[\"polarities\"].iloc[i] = \"10\"\n",
        "    elif df[\"polarity\"].iloc[i] != \"NEGATIVE\\n\":\n",
        "      df[\"polarities\"].iloc[i] = \"01\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "exwW7kBTqw05",
        "outputId": "937d5a5f-e06c-4f28-b348-d0957a791689"
      },
      "source": [
        "df = df[[\"content\", \"Pro Trump\", \"Pro Biden\", \"Neutral\", \"sarcasm\", \"polarities\"]]\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>Pro Trump</th>\n",
              "      <th>Pro Biden</th>\n",
              "      <th>Neutral</th>\n",
              "      <th>sarcasm</th>\n",
              "      <th>polarities</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>True #Trump got to the white working underclas...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Uh oh! @Twitter stops me from posting new emai...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gildan Now Available At The Lowest Price Of Th...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>So happy for our fellow Americans ,yâ€™all vot...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@NZim22 @CollinKelley @Fred_Jackson__ @realDon...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Maroon 5 - Memories (Cover by Donald Trump) ht...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>@Hk18mm Chung has become a hack on #FakeNews #...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>â€œNo matter how corrupt, greedy, and heartles...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>@RealJamesWoods We found #Biden’s voters... 💀😬...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Of course, Republicans who were ultra-concerne...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content  ...  polarities\n",
              "0  True #Trump got to the white working underclas...  ...          10\n",
              "1  Uh oh! @Twitter stops me from posting new emai...  ...          10\n",
              "2  Gildan Now Available At The Lowest Price Of Th...  ...          10\n",
              "3  So happy for our fellow Americans ,yâ€™all vot...  ...          10\n",
              "4  @NZim22 @CollinKelley @Fred_Jackson__ @realDon...  ...          00\n",
              "5  Maroon 5 - Memories (Cover by Donald Trump) ht...  ...          10\n",
              "6  @Hk18mm Chung has become a hack on #FakeNews #...  ...          00\n",
              "7  â€œNo matter how corrupt, greedy, and heartles...  ...          10\n",
              "8  @RealJamesWoods We found #Biden’s voters... 💀😬...  ...          01\n",
              "9  Of course, Republicans who were ultra-concerne...  ...          10\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhjnJEwKnISB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dd662ec-2e40-4eda-8aa3-5306fe855e19"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uorMX_zrnISM",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "25aacbce-25f2-4aaa-d26e-bc93ff0aab5b"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLcetMjZFjSH"
      },
      "source": [
        "## Load and Preprocess Training Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dal0ggBcYdD"
      },
      "source": [
        "Dataset will be tokenized then split into training and validation sets. The validation set will be used to monitor training. For testing a separate test set will be loaded for analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AhWrzX7nITB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e28fdc61-4e73-4b18-9a56-886009d8ce1e"
      },
      "source": [
        "print('Unique comments: ', df.content.nunique() == df.shape[0])\n",
        "print('Null values: ', df.isnull().values.any())\n",
        "# df[df.isna().any(axis=1)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique comments:  True\n",
            "Null values:  False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkKpz_9eJRt7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "612dbd4d-2cd8-4b04-9c2f-18181c83289f"
      },
      "source": [
        "print('average sentence length: ', df.content.str.split().str.len().mean())\n",
        "print('stdev sentence length: ', df.content.str.split().str.len().std())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average sentence length:  21.41232945932289\n",
            "stdev sentence length:  12.918652287556585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVI59S9VaAfB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59565b4c-8ea6-46f9-9b12-ea0d3c33ff97"
      },
      "source": [
        "cols = df.columns\n",
        "label_cols = ['Pro Trump', 'Pro Biden', 'Neutral']\n",
        "num_labels = len(label_cols)\n",
        "print('Label columns: ', label_cols)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label columns:  ['Pro Trump', 'Pro Biden', 'Neutral']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzgA5qQgYIBZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f051f180-615b-4520-b8f5-ee06b1703167"
      },
      "source": [
        "print('Count of 1 per label: \\n', df[label_cols].sum(), '\\n') # Label counts, may need to downsample or upsample\n",
        "print('Count of 0 per label: \\n', df[label_cols].eq(0).sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count of 1 per label: \n",
            " Pro Trump    502\n",
            "Pro Biden    717\n",
            "Neutral      760\n",
            "dtype: int64 \n",
            "\n",
            "Count of 0 per label: \n",
            " Pro Trump    1477\n",
            "Pro Biden    1262\n",
            "Neutral      1219\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFpSd4JzaAae"
      },
      "source": [
        "df = df.sample(frac=1).reset_index(drop=True) #shuffle rows"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DF3ddjej5vd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "2d909fd6-b0df-4636-fc71-7228a7e2b233"
      },
      "source": [
        "df['one_hot_labels'] = list(df[label_cols].values)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>Pro Trump</th>\n",
              "      <th>Pro Biden</th>\n",
              "      <th>Neutral</th>\n",
              "      <th>sarcasm</th>\n",
              "      <th>polarities</th>\n",
              "      <th>one_hot_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Spotted in #Soho #London #Trump 🤭 https://t.co...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>01</td>\n",
              "      <td>[0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ya fue Donald Trump</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>01</td>\n",
              "      <td>[0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>well if it is fraud, (puej ji, fue fraude): Do...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>00</td>\n",
              "      <td>[0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@alfonslopeztena @TheEconomist I get the impre...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>00</td>\n",
              "      <td>[0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>One of the worst president in the American his...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>00</td>\n",
              "      <td>[0, 1, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             content  ...  one_hot_labels\n",
              "0  Spotted in #Soho #London #Trump 🤭 https://t.co...  ...       [0, 0, 1]\n",
              "1                                Ya fue Donald Trump  ...       [0, 0, 1]\n",
              "2  well if it is fraud, (puej ji, fue fraude): Do...  ...       [0, 0, 1]\n",
              "3  @alfonslopeztena @TheEconomist I get the impre...  ...       [0, 0, 1]\n",
              "4  One of the worst president in the American his...  ...       [0, 1, 0]\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlhHifh5bW7e"
      },
      "source": [
        "labels = list(df.one_hot_labels.values)\n",
        "comments = list(df.content.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlMHfElhGJzc"
      },
      "source": [
        "Load the pretrained tokenizer that corresponds to your choice in model. e.g.,\n",
        "\n",
        "```\n",
        "BERT:\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) \n",
        "\n",
        "XLNet:\n",
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=False) \n",
        "\n",
        "RoBERTa:\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=False)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNsEu-vUur-4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "c346e68e5ca749e4bf3f1e03b1ce1296",
            "b77ff0a98bec4e4eb6cfaa03b6a5b763",
            "f8bcf8bee8fe48808afa01559f5a42d0",
            "97b6c27e71f44a3393285fb7a519d85c",
            "206af872b8184aec91354ebe8d362c56",
            "38b504c2e55b4ea692e1babb613d1bf1",
            "b3f2c6627f854b6cb32d840daec02a8a",
            "21e9a51e2a384d60886ce38577264d16"
          ]
        },
        "outputId": "ea01ca55-561f-45c9-db01-13e28bcaf021"
      },
      "source": [
        "max_length = 100\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) # tokenizer\n",
        "encodings = tokenizer.batch_encode_plus(comments,max_length=max_length,pad_to_max_length=True) # tokenizer's encoding method\n",
        "print('tokenizer outputs: ', encodings.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c346e68e5ca749e4bf3f1e03b1ce1296",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2155: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tokenizer outputs:  dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFzJJFlkVNNK"
      },
      "source": [
        "# len(encodings['token_type_ids'][0]), len(encodings['token_type_ids'][100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6CCLSjfur-9"
      },
      "source": [
        "input_ids = encodings['input_ids'] # tokenized and encoded sentences\n",
        "token_type_ids = encodings['token_type_ids'] # token type ids\n",
        "attention_masks = encodings['attention_mask'] # attention masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSOFbThlYcpb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ecd5776-f3ec-4e6d-8e9f-4fecde876066"
      },
      "source": [
        "# Identifying indices of 'one_hot_labels' entries that only occur once - this will allow us to stratify split our training data later\n",
        "label_counts = df.one_hot_labels.astype(str).value_counts()\n",
        "one_freq = label_counts[label_counts==1].keys()\n",
        "one_freq_idxs = sorted(list(df[df.one_hot_labels.astype(str).isin(one_freq)].index), reverse=True)\n",
        "print('df label indices with only one instance: ', one_freq_idxs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df label indices with only one instance:  []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQQ7CoOag_r7"
      },
      "source": [
        "# Gathering single instance inputs to force into the training set after stratified split\n",
        "one_freq_input_ids = [input_ids.pop(i) for i in one_freq_idxs]\n",
        "one_freq_token_types = [token_type_ids.pop(i) for i in one_freq_idxs]\n",
        "one_freq_attention_masks = [attention_masks.pop(i) for i in one_freq_idxs]\n",
        "one_freq_labels = [labels.pop(i) for i in one_freq_idxs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9PxAt48HRRj"
      },
      "source": [
        "Be sure to handle all classes during validation using \"stratify\" during train/validation split:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPFaq4ufnIT2"
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets\n",
        "\n",
        "train_inputs, validation_inputs, train_labels, validation_labels, train_token_types, validation_token_types, train_masks, validation_masks = train_test_split(input_ids, labels, token_type_ids,attention_masks,\n",
        "                                                            random_state=2020, test_size=0.20, stratify = labels)\n",
        "\n",
        "# Add one frequency data to train data\n",
        "train_inputs.extend(one_freq_input_ids)\n",
        "train_labels.extend(one_freq_labels)\n",
        "train_masks.extend(one_freq_attention_masks)\n",
        "train_token_types.extend(one_freq_token_types)\n",
        "\n",
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "train_token_types = torch.tensor(train_token_types)\n",
        "\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "validation_token_types = torch.tensor(validation_token_types)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRnuLna-nIT4"
      },
      "source": [
        "# Select a batch size for training. For fine-tuning with XLNet, the authors recommend a batch size of 32, 48, or 128. We will use 32 here to avoid memory issues.\n",
        "batch_size = 8\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels, train_token_types)\n",
        "\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels, validation_token_types)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiFRnP_ZTBFa"
      },
      "source": [
        "torch.save(validation_dataloader,'validation_data_loader')\n",
        "torch.save(train_dataloader,'train_data_loader')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncGteBuSFuZM"
      },
      "source": [
        "## Load Model & Set Params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0dL-Bz_NrGj"
      },
      "source": [
        "Load the appropriate model below, each model already contains a single dense layer for classification on top.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "BERT:\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\n",
        "\n",
        "XLNet:\n",
        "model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=num_labels)\n",
        "\n",
        "RoBERTa:\n",
        "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=num_labels)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ujk4k16DnIT6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b37cf67a6a1c4ee88e4938c2759de267",
            "a20bc41ef9b14cccbe66af1347018842",
            "03b95dd5c6d94bf59ef6fc029c751322",
            "922852ce574a4579abd694c12aa021bf",
            "60b825d0d3c1470fa050d3f011fa347f",
            "c16d049b1d9943359f254ea0f5241b2a",
            "7b3a6bb3158c4c7c939e16ddbd9ed710",
            "02c113aee49b41c1af2b66afb3ad9803",
            "32303fe679004ca3a38b56abff09e73e",
            "c4c0123141ba4fda9a1ad40c89e87521",
            "7b7c49c4f7ad4c3b823ce55e0a3dd9bb",
            "8cffda280e1041e4b070717aa6aedaea",
            "11969b969ff54b3ca55187624f39e556",
            "f07f98b22190476dab9db7a5ee170aa1",
            "a76b46cc520b4f9daebcd1bd0a9e23c3",
            "1e30866b5b2f4424ac5d2afbde43d9a4"
          ]
        },
        "outputId": "142afb54-fd95-4e54-875e-db61f3443799"
      },
      "source": [
        "# Load model, the pretrained model will include a single linear classification layer on top for classification. \n",
        "# model = AutoModel.from_pretrained(\"vinai/bertweet-base\", num_labels=num_labels)\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
        "# model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=num_labels)\n",
        "# model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=num_labels)\n",
        "# model.load_state_dict(torch.load('./models/bert_main'))\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b37cf67a6a1c4ee88e4938c2759de267",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "32303fe679004ca3a38b56abff09e73e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGE4gv9qfhRG"
      },
      "source": [
        "Setting custom optimization parameters for the AdamW optimizer https://huggingface.co/transformers/main_classes/optimizer_schedules.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsV8zwWYnIT9"
      },
      "source": [
        "# setting custom optimization parameters. You may implement a scheduler here as well.\n",
        "param_optimizer = list(model.named_parameters())\n",
        "\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "# no_decay = []\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOomZIEIoHOL"
      },
      "source": [
        "optimizer = AdamW(optimizer_grouped_parameters,lr=3e-5,correct_bias=True)\n",
        "# optimizer = AdamW(model.parameters(),lr=2e-5)  # Default optimization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRQQZ8zIFzLW"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDLZmEC_oKo3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ba82b9f-80d8-4b11-80dc-ecb0589ce65b"
      },
      "source": [
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 8\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "\n",
        "  # Training\n",
        "  \n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  model.train()\n",
        "\n",
        "  # Tracking variables\n",
        "  tr_loss = 0 #running loss\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    optimizer.zero_grad()\n",
        "    # print(b_labels)\n",
        "    # # Forward pass for multiclass classification\n",
        "    # outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "    # loss = outputs[0]\n",
        "    # logits = outputs[1]\n",
        "\n",
        "    # Forward pass for multilabel classification\n",
        "    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    logits = outputs[0]\n",
        "    loss_func = BCEWithLogitsLoss() \n",
        "    loss = loss_func(logits.view(-1,num_labels),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
        "    loss_func = BCELoss() \n",
        "    loss = loss_func(torch.sigmoid(logits.view(-1,num_labels)),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
        "    train_loss_set.append(loss.item())    \n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    optimizer.step()\n",
        "    # scheduler.step()\n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "  # Validation\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Variables to gather full output\n",
        "  logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
        "\n",
        "  # Predict\n",
        "  for i, batch in enumerate(validation_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
        "    with torch.no_grad():\n",
        "      # Forward pass\n",
        "      outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "      b_logit_pred = outs[0]\n",
        "      pred_label = torch.sigmoid(b_logit_pred)\n",
        "\n",
        "      b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
        "      pred_label = pred_label.to('cpu').numpy()\n",
        "      b_labels = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tokenized_texts.append(b_input_ids)\n",
        "    logit_preds.append(b_logit_pred)\n",
        "    true_labels.append(b_labels)\n",
        "    pred_labels.append(pred_label)\n",
        "\n",
        "  # Flatten outputs\n",
        "  pred_labels = [item for sublist in pred_labels for item in sublist]\n",
        "  true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  threshold = 0.5\n",
        "  pred_bools = [pl>threshold for pl in pred_labels]\n",
        "  true_bools = [tl==1 for tl in true_labels]\n",
        "  val_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')*100\n",
        "  val_flat_accuracy = accuracy_score(true_bools, pred_bools)*100\n",
        "\n",
        "  print('F1 Validation Accuracy: ', val_f1_accuracy)\n",
        "  print('Flat Validation Accuracy: ', val_flat_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/8 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.6081157150593671\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  12%|█▎        | 1/8 [00:36<04:12, 36.02s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  52.81803542673108\n",
            "Flat Validation Accuracy:  41.41414141414141\n",
            "Train loss: 0.4925930243399408\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  25%|██▌       | 2/8 [01:12<03:37, 36.30s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  57.534246575342465\n",
            "Flat Validation Accuracy:  47.72727272727273\n",
            "Train loss: 0.3733011774267211\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  38%|███▊      | 3/8 [01:49<03:01, 36.23s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  67.66712141882674\n",
            "Flat Validation Accuracy:  62.37373737373737\n",
            "Train loss: 0.21001327669981754\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  50%|█████     | 4/8 [02:25<02:25, 36.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  65.88845654993514\n",
            "Flat Validation Accuracy:  63.13131313131313\n",
            "Train loss: 0.1189634958940624\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  62%|██████▎   | 5/8 [03:01<01:48, 36.30s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  65.63706563706563\n",
            "Flat Validation Accuracy:  64.14141414141415\n",
            "Train loss: 0.07733606595564822\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  75%|███████▌  | 6/8 [03:38<01:12, 36.30s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  66.66666666666666\n",
            "Flat Validation Accuracy:  64.64646464646465\n",
            "Train loss: 0.04309713887050748\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  88%|████████▊ | 7/8 [04:14<00:36, 36.33s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  68.97435897435898\n",
            "Flat Validation Accuracy:  67.17171717171718\n",
            "Train loss: 0.04988433800477798\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 8/8 [04:50<00:00, 36.36s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "F1 Validation Accuracy:  64.85084306095979\n",
            "Flat Validation Accuracy:  62.878787878787875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiBeiBSRoOuz"
      },
      "source": [
        "torch.save(model.state_dict(), 'bert_model_toxic')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7dd2GE3F4yK"
      },
      "source": [
        "## Load and Preprocess Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW6MsCuFHeOE"
      },
      "source": [
        "#DELETE LATER\n",
        "# test_df = pd.read_csv('testset_new.csv')\n",
        "test_df = pd.read_csv('test_main.csv')\n",
        "print(test_df.shape)\n",
        "test_df.dropna()\n",
        "print(test_df.shape)\n",
        "# test_df.drop(columns='content', inplace=True)\n",
        "# test_df = test_df.rename(columns={'content': 'tweet', 'Against Trump': 'Anti Trump', 'Against Biden': 'Anti Biden'})\n",
        "test_label_cols = ['Pro Trump', 'Pro Biden', 'Neutral']\n",
        "test_df['Pro Trump'] = np.nan\n",
        "test_df['Pro Biden'] = np.nan\n",
        "test_df['Neutral'] = np.nan\n",
        "\n",
        "print(test_label_cols)\n",
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77rjCrMGpYxz"
      },
      "source": [
        "test_df = test_df[~test_df[test_label_cols].eq(-1).any(axis=1)] #remove irrelevant rows/comments with -1 values\n",
        "test_df['one_hot_labels'] = list(test_df[test_label_cols].values)\n",
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a41OmU2i7qp"
      },
      "source": [
        "# Gathering input data\n",
        "test_labels = list(test_df.one_hot_labels.values)\n",
        "test_comments = list(test_df.content.values)\n",
        "# print(test_comments)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amySMO8EQzf2"
      },
      "source": [
        "# Encoding input data\n",
        "%%time\n",
        "test_encodings = tokenizer.batch_encode_plus(test_comments,max_length=max_length,pad_to_max_length=True)\n",
        "test_input_ids = test_encodings['input_ids']\n",
        "test_token_type_ids = test_encodings['token_type_ids']\n",
        "test_attention_masks = test_encodings['attention_mask']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqOfi9fkRaRN"
      },
      "source": [
        "# Make tensors out of data\n",
        "test_inputs = torch.tensor(test_input_ids)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "test_masks = torch.tensor(test_attention_masks)\n",
        "test_token_types = torch.tensor(test_token_type_ids)\n",
        "# Create test dataloader\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels, test_token_types)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=8)\n",
        "# Save test dataloader\n",
        "torch.save(test_dataloader,'test_data_loader')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFTWxCA_GBau"
      },
      "source": [
        "## Prediction and Metics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPvrL6OFSQvf"
      },
      "source": [
        "# Test\n",
        "# Put model in evaluation mode to evaluate loss on the validation set\n",
        "model.eval()\n",
        "\n",
        "#track variables\n",
        "logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
        "\n",
        "# Predict\n",
        "for i, batch in enumerate(test_dataloader):\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
        "  with torch.no_grad():\n",
        "    # Forward pass\n",
        "    outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    b_logit_pred = outs[0]\n",
        "    pred_label = torch.sigmoid(b_logit_pred)\n",
        "\n",
        "    b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
        "    pred_label = pred_label.to('cpu').numpy()\n",
        "    b_labels = b_labels.to('cpu').numpy()\n",
        "\n",
        "  tokenized_texts.append(b_input_ids)\n",
        "  logit_preds.append(b_logit_pred)\n",
        "  true_labels.append(b_labels)\n",
        "  pred_labels.append(pred_label)\n",
        "\n",
        "# Flatten outputs\n",
        "tokenized_texts = [item for sublist in tokenized_texts for item in sublist]\n",
        "pred_labels = [item for sublist in pred_labels for item in sublist]\n",
        "true_labels = [item for sublist in true_labels for item in sublist]\n",
        "# Converting flattened binary values to boolean values\n",
        "true_bools = [tl==1 for tl in true_labels]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQeGWqeMzAoZ"
      },
      "source": [
        "We need to threshold our sigmoid function outputs which range from [0, 1]. Below I use 0.50 as a threshold."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eoOvfa5zjqm"
      },
      "source": [
        "# Metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZcZUcYOxxmM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d791075-60c0-46b5-a98f-10b287aab38e"
      },
      "source": [
        "pred_bools = [pl>0.50 for pl in pred_labels] #boolean output after thresholding\n",
        "\n",
        "# Print and save classification report\n",
        "# print('F1 Validation Accuracy: ', val_f1_accuracy)\n",
        "# print('Flat Validation Accuracy: ', val_flat_accuracy,'\\n')\n",
        "print('Test F1 Accuracy: ', f1_score(true_bools, pred_bools,average='micro'))\n",
        "print('Test Flat Accuracy: ', accuracy_score(true_bools, pred_bools),'\\n')\n",
        "clf_report = classification_report(true_bools,pred_bools,target_names=test_label_cols)\n",
        "pickle.dump(clf_report, open('classification_report.txt','wb')) #save report\n",
        "print(clf_report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test F1 Accuracy:  0.0\n",
            "Test Flat Accuracy:  0.04619033965018377 \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Pro Trump       0.00      0.00      0.00         0\n",
            "   Pro Biden       0.00      0.00      0.00         0\n",
            "     Neutral       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.00      0.00      0.00         0\n",
            "   macro avg       0.00      0.00      0.00         0\n",
            "weighted avg       0.00      0.00      0.00         0\n",
            " samples avg       0.00      0.00      0.00         0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rLqrHK87eir"
      },
      "source": [
        "## Output Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJBkRdGN1hzx"
      },
      "source": [
        "idx2label = dict(zip(range(6),label_cols))\n",
        "print(idx2label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZUglV_A4BF_"
      },
      "source": [
        "# Getting indices of where boolean one hot vector true_bools is True so we can use idx2label to gather label names\n",
        "true_label_idxs, pred_label_idxs=[],[]\n",
        "for vals in true_bools:\n",
        "  true_label_idxs.append(np.where(vals)[0].flatten().tolist())\n",
        "for vals in pred_bools:\n",
        "  pred_label_idxs.append(np.where(vals)[0].flatten().tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOGhXM3R4a91"
      },
      "source": [
        "# Gathering vectors of label names using idx2label\n",
        "true_label_texts, pred_label_texts = [], []\n",
        "for vals in true_label_idxs:\n",
        "  if vals:\n",
        "    true_label_texts.append([idx2label[val] for val in vals])\n",
        "  else:\n",
        "    true_label_texts.append(vals)\n",
        "\n",
        "for vals in pred_label_idxs:\n",
        "  if vals:\n",
        "    pred_label_texts.append([idx2label[val] for val in vals])\n",
        "  else:\n",
        "    pred_label_texts.append(vals)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HaqV6pn_HCG"
      },
      "source": [
        "# Decoding input ids to comment text\n",
        "comment_texts = [tokenizer.decode(text,skip_special_tokens=True,clean_up_tokenization_spaces=False) for text in tokenized_texts]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7kk0Mgl1L-T"
      },
      "source": [
        "# Converting lists to df\n",
        "comparisons_df = pd.DataFrame({'comment_text': comment_texts, 'true_labels': true_label_texts, 'pred_labels':pred_label_texts})\n",
        "comparisons_df.to_csv('comparisons.csv')\n",
        "comparisons_df.sample(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRVf66L3boV4"
      },
      "source": [
        "def temp(x):\n",
        "  if x:\n",
        "    return x[0]\n",
        "  else:\n",
        "    return np.nan\n",
        "\n",
        "test_df['sentiment'] = comparisons_df['pred_labels']\n",
        "test_df['sentiment'] = test_df['sentiment'].apply(lambda col: temp(col))\n",
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NBUWMFbePtS"
      },
      "source": [
        "print(test_df.shape)\n",
        "test_df.dropna(subset=['sentiment'], inplace=True)\n",
        "print(test_df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2aO-5jDhMkU"
      },
      "source": [
        "test_df.groupby(['country', 'sentiment']).agg(['count', 'sum'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGYjVTLGe_qV"
      },
      "source": [
        "test_df = test_df[test_df['sentiment'] != 'Neutral']\n",
        "print(test_df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36c9ntxJfMpy"
      },
      "source": [
        "del test_df['Pro Trump']\n",
        "del test_df['Pro Biden']\n",
        "del test_df['Neutral']\n",
        "del test_df['one_hot_labels']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecLHLdFqfkPU"
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIb0M3o_m4lf"
      },
      "source": [
        "test_df.to_csv('tempBeforeSolr.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6mDy1lw0S4y"
      },
      "source": [
        "Doing this may result in a trade offs between precision, flat accuracy and micro F1 accuracy. You may tune the threshold however you want."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHlhb2lvar8V"
      },
      "source": [
        "# Calculate Accuracy - maximize F1 accuracy by tuning threshold values. First with 'macro_thresholds' on the order of e^-1 then with 'micro_thresholds' on the order of e^-2\n",
        "\n",
        "macro_thresholds = np.array(range(1,10))/10\n",
        "\n",
        "f1_results, flat_acc_results = [], []\n",
        "for th in macro_thresholds:\n",
        "  pred_bools = [pl>th for pl in pred_labels]\n",
        "  test_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')\n",
        "  test_flat_accuracy = accuracy_score(true_bools, pred_bools)\n",
        "  f1_results.append(test_f1_accuracy)\n",
        "  flat_acc_results.append(test_flat_accuracy)\n",
        "\n",
        "best_macro_th = macro_thresholds[np.argmax(f1_results)] #best macro threshold value\n",
        "\n",
        "micro_thresholds = (np.array(range(10))/100)+best_macro_th #calculating micro threshold values\n",
        "\n",
        "f1_results, flat_acc_results = [], []\n",
        "for th in micro_thresholds:\n",
        "  pred_bools = [pl>th for pl in pred_labels]\n",
        "  test_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')\n",
        "  test_flat_accuracy = accuracy_score(true_bools, pred_bools)\n",
        "  f1_results.append(test_f1_accuracy)\n",
        "  flat_acc_results.append(test_flat_accuracy)\n",
        "\n",
        "best_f1_idx = np.argmax(f1_results) #best threshold value\n",
        "\n",
        "# Printing and saving classification report\n",
        "print('Best Threshold: ', micro_thresholds[best_f1_idx])\n",
        "print('Test F1 Accuracy: ', f1_results[best_f1_idx])\n",
        "print('Test Flat Accuracy: ', flat_acc_results[best_f1_idx], '\\n')\n",
        "\n",
        "best_pred_bools = [pl>micro_thresholds[best_f1_idx] for pl in pred_labels]\n",
        "clf_report_optimized = classification_report(true_bools,best_pred_bools, target_names=label_cols)\n",
        "pickle.dump(clf_report_optimized, open('classification_report_optimized.txt','wb'))\n",
        "print(clf_report_optimized)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}