{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sarcasm Inference.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6WmPYmzsrt_"
      },
      "source": [
        "!pip install transformers==4.3.3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "from torch.nn import BCEWithLogitsLoss, BCELoss\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score\n",
        "from transformers import AutoModel, AutoTokenizer \n",
        "import pickle\n",
        "from transformers import *\n",
        "from tqdm import tqdm, trange\n",
        "from ast import literal_eval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbNW_wO5sz3c"
      },
      "source": [
        "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5l4seQ7Ys3QQ"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Xhi_jZbs6Im"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import tqdm\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from wordcloud import WordCloud\n",
        "from nltk.corpus import stopwords\n",
        "from tqdm.notebook import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import tensorflow_hub as hub\n",
        "import tokenization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xc031k6taYZ"
      },
      "source": [
        "raw_df = pd.read_csv('train_unbalanced_final.csv')\n",
        "raw_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-x83XOXmtawj"
      },
      "source": [
        "print(raw_df.shape)\n",
        "df = raw_df[['content', 'Pro Trump', 'Pro Biden', 'Neutral']]\n",
        "df = df[df['Pro Biden'].notna()]\n",
        "df = df[df['content'].notna()]\n",
        "df = df[df['Pro Trump'].notna()]\n",
        "df = df[df['Neutral'].notna()]\n",
        "print(df.shape)\n",
        "df = df.astype({\"Pro Trump\": int, \"Pro Biden\": int, \"Neutral\": int})\n",
        "df.drop_duplicates(subset='content', keep='first', inplace=True)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNcGmOJSteIL"
      },
      "source": [
        "df = df.sample(frac=1).reset_index(drop=True) #shuffle rows"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MyDO77ltnys"
      },
      "source": [
        "df['one_hot_labels'] = list(df[label_cols].values)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrgK9WCEtr9e"
      },
      "source": [
        "labels = list(df.one_hot_labels.values)\n",
        "comments = list(df.content.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUp0Vvxysf5D"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE89oI16soBb"
      },
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow_hub as hub\n",
        "# Recreate the exact same model, including its weights and the optimizer\n",
        "sarcasm_model = keras.models.load_model('/content/gdrive/MyDrive/Info Retrieval/Sarcasm Detection/model.h5',custom_objects={'KerasLayer':hub.KerasLayer})\n",
        "\n",
        "# Show the model architecture\n",
        "sarcasm_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NO0jeu5dsqwf"
      },
      "source": [
        "def bert_encode(texts, tokenizer, max_len=512):\n",
        "    all_tokens, all_masks, all_segments = [], [], []\n",
        "    \n",
        "    for text in tqdm(texts):\n",
        "        # Tokenize the current text\n",
        "        text = tokenizer.tokenize(text)\n",
        "        # Select text only till \n",
        "        text = text[:max_len-2]\n",
        "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
        "        pad_len = max_len - len(input_sequence)\n",
        "        \n",
        "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
        "        tokens += [0] * pad_len\n",
        "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
        "        segment_ids = [0] * max_len\n",
        "        \n",
        "        all_tokens.append(tokens)\n",
        "        all_masks.append(pad_masks)\n",
        "        all_segments.append(segment_ids)\n",
        "    \n",
        "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-kwf325tE33"
      },
      "source": [
        "%%time\n",
        "url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\n",
        "bert_layer = hub.KerasLayer(url, trainable=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX4M_MDitHiA"
      },
      "source": [
        "# Get tokenizer\n",
        "vocab_fl = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = tokenization.FullTokenizer(vocab_fl, lower_case)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tijG2c26tJby"
      },
      "source": [
        "train_input = bert_encode(df['content'].values, tokenizer, max_len=160)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlgoTjqttLuv"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjmNxgRjtNum"
      },
      "source": [
        "predictions = sarcasm_model.predict(train_input)\n",
        "print(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxMnlNW2tQDw"
      },
      "source": [
        "# Generate arg maxes for predictions\n",
        "classes = np.argmax(predictions, axis = 1)\n",
        "print(classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ty-bUntHtyFz"
      },
      "source": [
        "df['sarcasm_labels'] = classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxti9qfIt0lD"
      },
      "source": [
        "def encode_target(t_class):\n",
        "    t_class=str(t_class)\n",
        "    class_dict = {\n",
        "        '0':'sarcasm',\n",
        "        '1':'sarcasm',\n",
        "        '2':'regular',\n",
        "        '3':'sarcasm'\n",
        "    }\n",
        "    return class_dict[t_class]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqC5BJJjt2wL"
      },
      "source": [
        "df[\"sarcasm_labels\"] = df['sarcasm_labels'].apply(lambda x: encode_target(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S-7aYrDt47L"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsbVezHQt6tR"
      },
      "source": [
        "count = df['sarcasm_labels'].value_counts()\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCT5YI9Vt9Ht"
      },
      "source": [
        "df.to_csv('train_with_sarcasm.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plR0zhYgt_TX"
      },
      "source": [
        "df_sarcasm = df[(df['sarcasm_labels'] == 'sarcasm')]\n",
        "df_sarcasm.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TGmmIt2uA4G"
      },
      "source": [
        "df_sarcasm.to_csv('sarcasm_only.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}